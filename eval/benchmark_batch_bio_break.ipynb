{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/data/DBP_sa_bc/\")\n",
    "from os.path import join as pj\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append(\"modules\")\n",
    "import utils\n",
    "import numpy as np\n",
    "import scib\n",
    "import scib.metrics as me\n",
    "import anndata as ad\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='lung_ts')\n",
    "parser.add_argument('--experiment', type=str, default='e54')\n",
    "parser.add_argument('--model', type=str, default='default')\n",
    "parser.add_argument('--init_model', type=str, default='sp_00001899')\n",
    "parser.add_argument('--method', type=str, default='DBP_sa_bc')\n",
    "parser.add_argument('--K', type=int, default='41')\n",
    "o, _ = parser.parse_known_args()  # for python interactive\n",
    "# o = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = o.K\n",
    "break_index_dir = pj(\"result\", o.task, o.experiment, o.model, \"predict\", o.init_model)\n",
    "\n",
    "if \"DBP_sa_bc\" in o.method:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method, o.experiment, o.init_model)\n",
    "else:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method)\n",
    "cfg_task = re.sub(\"_atlas|_generalize|_transfer|_ref_.*\", \"\", o.task)\n",
    "data_config = utils.load_toml(\"configs/data.toml\")[cfg_task]\n",
    "for k, v in data_config.items():\n",
    "    vars(o)[k] = v\n",
    "model_config = utils.load_toml(\"configs/model.toml\")[\"default\"]\n",
    "if o.model != \"default\":\n",
    "    model_config.update(utils.load_toml(\"configs/model.toml\")[o.model])\n",
    "for k, v in model_config.items():\n",
    "    vars(o)[k] = v\n",
    "o.s_joint, o.combs, *_ = utils.gen_all_batch_ids(o.s_joint, o.combs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cell type labels\n",
    "if o.task == \"hae\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"labels.csv\"))\n",
    "        labels += utils.transpose_list(label)[13][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "elif o.task == \"wnn_rna\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"meta.csv\"))\n",
    "        labels += utils.transpose_list(label)[10][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "elif o.task == \"lung_ts\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"meta.csv\"))\n",
    "        labels += utils.transpose_list(label)[13][1:]\n",
    "        # labels += utils.transpose_list(label)[14][1:]\n",
    "    # replacements = {'Alveolar_Type1':'Alveolar', 'Alveolar_Type2':'Alveolar', \n",
    "    #                 'B_cell_mature':'B', 'B_cell_naive':'B', \n",
    "    #                 'Basal':'Basal', 'Blood_vessel':'Blood_vessel', \n",
    "    #                 'Ciliated':'Ciliated', 'DC_1':'DC',\n",
    "    #                 'DC_2':'DC', 'DC_Monocyte_Dividing':'DC_Monocyte_Dividing',\n",
    "    #                 'DC_activated':'DC_activated', 'DC_plasmacytoid':'DC_plasmacytoid', \n",
    "    #                 'Fibroblast':'Fibroblast', 'Lymph_vessel':'Lymph_vessel',\n",
    "    #                 'Macrophage_Dividing':'Macrophag', 'Macrophage_MARCOneg':'Macrophag', \n",
    "    #                 'Macrophage_MARCOpos':'Macrophag', 'Mast_cells':'Mast_cells', \n",
    "    #                 'Monocyte':'Monocyte', 'Muscle_cells' :'Muscle_cells',\n",
    "    #                 'NK':'NK', 'NK_Dividing':'NK', \n",
    "    #                 'Plasma_cells':'Plasma_cells', 'Secretory_club':'Secretory_club', \n",
    "    #                 'T_CD4':'T_CD4', 'T_CD8_CytT':'T_CD8_CytT', \n",
    "    #                 'T_cells_Dividing' :'T', 'T_regulatory':'T'}\n",
    "    # replaced_list = [replacements[value] if value in replacements else value for value in labels]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predicted latent variables\n",
    "o.mods = [\"rna\"]\n",
    "o.pred_dir = pj(\"result\", o.task, o.experiment, o.model, \"predict\", o.init_model)\n",
    "pred = utils.load_predicted(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if o.method in [\"DBP_sa_bc\", \"mofa\", \"scmomat\", \"stabmap\", \"scvaeit\"]:\n",
    "    output_type = \"embed\"\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    output_type = \"graph\"\n",
    "else:\n",
    "    assert False, o.method+\": invalid method!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = \"X_emb\"\n",
    "batch_key = \"batch\"\n",
    "label_key = \"label\"\n",
    "cluster_key = \"cluster\"\n",
    "si_metric = \"euclidean\"\n",
    "subsample = 0.5\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pred[\"w\"][\"joint\"]\n",
    "c = pred[\"z\"][\"joint\"][:, :o.dim_c]*w\n",
    "s = pred[\"s\"][\"joint\"]\n",
    "index = np.loadtxt(pj(break_index_dir, \"break_index.csv\"), delimiter=\",\", dtype=int)\n",
    "c_ord = c[:,index]\n",
    "c_bre = c_ord[:, :K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if o.method == \"DBP_sa_bc\":\n",
    "    adata = ad.AnnData(c_bre)\n",
    "    adata.obsm[embed] = c_bre\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"mofa\", \"stabmap\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings)[1:, 1:].astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"scmomat\", \"scvaeit\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings).astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    adata.obsp[\"connectivities\"] = scipy.io.mmread(pj(result_dir, \"connectivities.mtx\")).tocsr()\n",
    "    adata.uns[\"neighbors\"] = {'connectivities_key': 'connectivities'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "print('clustering...')\n",
    "res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "    cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "\n",
    "results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "results['batch_ASW'] = me.silhouette_batch(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, verbose=verbose)\n",
    "print(\"batch_ASW: \" + str(results['batch_ASW']))\n",
    "\n",
    "type_ = \"knn\" if output_type == \"graph\" else None\n",
    "results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "    type_=type_, verbose=verbose)\n",
    "print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "# results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "#     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# print(\"iLISI: \" + str(results['iLISI']))\n",
    "results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "    subsample=subsample*100, verbose=verbose)\n",
    "print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "\n",
    "results['label_ASW'] = me.silhouette(adata, label_key=label_key, embed=embed)\n",
    "print(\"label_ASW: \" + str(results['label_ASW']))\n",
    "\n",
    "results['il_score_ASW'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, cluster=False, verbose=verbose)\n",
    "print(\"il_score_ASW: \" + str(results['il_score_ASW']))\n",
    "\n",
    "results['il_score_f1'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, cluster=True, verbose=verbose)\n",
    "print(\"il_score_f1: \" + str(results['il_score_f1']))\n",
    "\n",
    "results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "    subsample=subsample*100,  verbose=verbose)\n",
    "print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# results = {k: float(v) for k, v in results.items()}\n",
    "# results['batch_score'] = np.nanmean([results['graph_conn'], results['batch_ASW'], results['kBET'], results['iLISI']])\n",
    "# results['bio_score'] = np.nanmean([results['label_ASW'], results['il_score_ASW'], results['il_score_f1'], \n",
    "#                                    results['NMI'], results['ARI'], results['cLISI']])\n",
    "# results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'graph_conn':     [results['graph_conn']],\n",
    "    'batch_ASW':      [results['batch_ASW']],\n",
    "    'kBET':           [results['kBET']],\n",
    "    'iLISI':          [results['iLISI']],\n",
    "    # 'batch_score':    [results['batch_score']],\n",
    "    'label_ASW':      [results['label_ASW']],\n",
    "    'il_score_ASW':   [results['il_score_ASW']],\n",
    "    'il_score_f1':    [results['il_score_f1']],   \n",
    "    'NMI':            [results['NMI']],\n",
    "    'ARI':            [results['ARI']],\n",
    "    'cLISI':          [results['cLISI']],\n",
    "    # 'bio_score':      [results['bio_score']],\n",
    "    # 'overall_score':  [results['overall_score']]\n",
    "})\n",
    "print(df)\n",
    "utils.mkdirs(result_dir, remove_old=False)\n",
    "df.to_excel(pj(result_dir, \"metrics_batch_bio_break\"+str(o.K)+\".xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "\n",
    "# print('clustering...')\n",
    "# res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "#     cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "\n",
    "# results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "# print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "# results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "# print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "# type_ = \"knn\" if output_type == \"graph\" else None\n",
    "# results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "#     type_=type_, verbose=verbose)\n",
    "# print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "# results['il_score_f1'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "#     embed=embed, cluster=True, verbose=verbose)\n",
    "# print(\"il_score_f1: \" + str(results['il_score_f1']))\n",
    "\n",
    "# results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "# print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "# # results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "# #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# # print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "#     subsample=subsample*100,  verbose=verbose)\n",
    "# print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# # results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "# #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# # print(\"iLISI: \" + str(results['iLISI']))\n",
    "# results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "#     subsample=subsample*100, verbose=verbose)\n",
    "# print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "# results = {k: float(v) for k, v in results.items()}\n",
    "# results['batch_score'] = np.nanmean([results['iLISI'], results['graph_conn'], results['kBET']])\n",
    "# results['bio_score'] = np.nanmean([results['NMI'], results['ARI'], results['il_score_f1'], results['cLISI']])\n",
    "# results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'iLISI':          [results['iLISI']],\n",
    "#     'graph_conn':     [results['graph_conn']],\n",
    "#     'kBET':           [results['kBET']],\n",
    "#     'batch_score':    [results['batch_score']],\n",
    "#     'NMI':            [results['NMI']],\n",
    "#     'ARI':            [results['ARI']],\n",
    "#     'il_score_f1':    [results['il_score_f1']],\n",
    "#     'cLISI':          [results['cLISI']],\n",
    "#     'bio_score':      [results['bio_score']],\n",
    "#     'overall_score':  [results['overall_score']]\n",
    "# })\n",
    "# print(df)\n",
    "# utils.mkdirs(result_dir, remove_old=False)\n",
    "# df.to_excel(pj(result_dir, \"metrics_batch_bio_break_k150.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
