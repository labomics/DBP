{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/data/DBP_sa_bc/\")\n",
    "from os.path import join as pj\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append(\"modules\")\n",
    "import utils\n",
    "import numpy as np\n",
    "import scib\n",
    "import scib.metrics as me\n",
    "import anndata as ad\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='wnn_rna')\n",
    "parser.add_argument('--experiment', type=str, default='e1')\n",
    "parser.add_argument('--model', type=str, default='default')\n",
    "parser.add_argument('--init_model', type=str, default='sp_00001899')\n",
    "parser.add_argument('--method', type=str, default='harmony')\n",
    "parser.add_argument('--K', type=str, default='20')\n",
    "# parser.add_argument('--method', type=str, default='midas_embed')\n",
    "o, _ = parser.parse_known_args()  # for python interactive\n",
    "# o = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DBP_sa_bc\" in o.method:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method, o.experiment, o.init_model)\n",
    "else:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method, o.K)\n",
    "cfg_task = re.sub(\"_atlas|_generalize|_transfer|_ref_.*\", \"\", o.task)\n",
    "data_config = utils.load_toml(\"configs/data.toml\")[cfg_task]\n",
    "for k, v in data_config.items():\n",
    "    vars(o)[k] = v\n",
    "model_config = utils.load_toml(\"configs/model.toml\")[\"default\"]\n",
    "if o.model != \"default\":\n",
    "    model_config.update(utils.load_toml(\"configs/model.toml\")[o.model])\n",
    "for k, v in model_config.items():\n",
    "    vars(o)[k] = v\n",
    "o.s_joint, o.combs, *_ = utils.gen_all_batch_ids(o.s_joint, o.combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'CD4 T' 'CD8 T' 'DC' 'Mono' 'NK' 'other' 'other T']\n"
     ]
    }
   ],
   "source": [
    "# Load cell type labels\n",
    "if o.task == \"hae\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"labels.csv\"))\n",
    "        labels += utils.transpose_list(label)[13][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "elif o.task == \"wnn_rna\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"meta.csv\"))\n",
    "        labels += utils.transpose_list(label)[10][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "elif o.task == \"lung_ts\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"meta.csv\"))\n",
    "        labels += utils.transpose_list(label)[13][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "elif o.task == \"wnn_rnas7\":\n",
    "    labels = []\n",
    "    for raw_data_dir in o.raw_data_dirs:\n",
    "        label = utils.load_csv(pj(raw_data_dir, \"label\", \"meta.csv\"))\n",
    "        labels += utils.transpose_list(label)[10][1:]\n",
    "    labels = np.array(labels)\n",
    "    print(np.unique(labels))\n",
    "    # labels = []\n",
    "    # for raw_data_dir in o.raw_data_dirs:\n",
    "    #     label = utils.load_csv(pj(raw_data_dir, \"label_seurat\", \"l1.csv\"))\n",
    "    #     labels += utils.transpose_list(label)[1][1:]\n",
    "    # labels = np.array(labels)\n",
    "    # print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predicted variables ...\n",
      "Loading subset 0: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 47.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 0: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 87.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 0: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 1: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 42.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 1: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 92.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 1: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 2: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 54.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 2: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 76.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 2: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 3: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 41.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 3: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 29.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 3: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 4: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 39.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 4: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 133.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 4: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 5: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 93.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 5: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 84.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 5: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 6: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 69.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 6: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 140.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 6: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 7: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 54.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 7: w, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 45.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 7: A, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to numpy ...\n",
      "Converting subset 0: s, joint\n",
      "Converting subset 0: z, joint\n",
      "Converting subset 0: w, joint\n",
      "Converting subset 0: A, joint\n",
      "Converting subset 1: s, joint\n",
      "Converting subset 1: z, joint\n",
      "Converting subset 1: w, joint\n",
      "Converting subset 1: A, joint\n",
      "Converting subset 2: s, joint\n",
      "Converting subset 2: z, joint\n",
      "Converting subset 2: w, joint\n",
      "Converting subset 2: A, joint\n",
      "Converting subset 3: s, joint\n",
      "Converting subset 3: z, joint\n",
      "Converting subset 3: w, joint\n",
      "Converting subset 3: A, joint\n",
      "Converting subset 4: s, joint\n",
      "Converting subset 4: z, joint\n",
      "Converting subset 4: w, joint\n",
      "Converting subset 4: A, joint\n",
      "Converting subset 5: s, joint\n",
      "Converting subset 5: z, joint\n",
      "Converting subset 5: w, joint\n",
      "Converting subset 5: A, joint\n",
      "Converting subset 6: s, joint\n",
      "Converting subset 6: z, joint\n",
      "Converting subset 6: w, joint\n",
      "Converting subset 6: A, joint\n",
      "Converting subset 7: s, joint\n",
      "Converting subset 7: z, joint\n",
      "Converting subset 7: w, joint\n",
      "Converting subset 7: A, joint\n"
     ]
    }
   ],
   "source": [
    "# Load predicted latent variables\n",
    "o.mods = [\"rna\"]\n",
    "o.pred_dir = pj(\"result\", o.task, o.experiment, o.model, \"predict\", o.init_model)\n",
    "pred = utils.load_predicted(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if o.method in [\"DBP_sa_bc\", \"mofa\", \"harmony\", \"liger\", \"scETM\", \"scanorama_embed\", \"seurat_rpca\", \"seurat_cca\", \"pca\", \"LDVAE\"]:\n",
    "    output_type = \"embed\"\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    output_type = \"graph\"\n",
    "else:\n",
    "    assert False, o.method+\": invalid method!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = \"X_emb\"\n",
    "batch_key = \"batch\"\n",
    "label_key = \"label\"\n",
    "cluster_key = \"cluster\"\n",
    "si_metric = \"euclidean\"\n",
    "subsample = 0.5\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pred[\"w\"][\"joint\"]\n",
    "c = pred[\"z\"][\"joint\"][:, :o.dim_c]*w\n",
    "s = pred[\"s\"][\"joint\"]\n",
    "\n",
    "if o.method == \"DBP_sa_bc\":\n",
    "    adata = ad.AnnData(c)\n",
    "    adata.obsm[embed] = c\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"mofa\", \"harmony\", \"liger\", \"scanorama_embed\", \"seurat_rpca\", \"seurat_cca\", \"pca\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings)[1:, 1:].astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"scETM\", \"LDVAE\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings).astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    adata.obsp[\"connectivities\"] = scipy.io.mmread(pj(result_dir, \"connectivities.mtx\")).tocsr()\n",
    "    adata.uns[\"neighbors\"] = {'connectivities_key': 'connectivities'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated function (or staticmethod) opt_louvain.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_conn: 0.9514722402564708\n",
      "batch_ASW: 0.9008520102784057\n",
      "Adding diffusion to step 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:264: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  category=DeprecationWarning)\n",
      "/root/anaconda3/lib/python3.7/site-packages/rpy2/robjects/numpy2ri.py:188: DeprecationWarning: The global conversion available with activate() is deprecated and will be removed in the next major release. Use a local converter.\n",
      "  category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding diffusion to step 4\n",
      "Adding diffusion to step 4\n",
      "Adding diffusion to step 5\n",
      "Adding diffusion to step 4\n",
      "Adding diffusion to step 4\n",
      "kBET: 0.2698172021895944\n",
      "iLISI: 0.5061031894126949\n",
      "label_ASW: 0.6529103815555573\n",
      "il_score_ASW: 0.5875662091712002\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n",
      "Compute neighbors on rep X_emb\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "print('clustering...')\n",
    "res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "    cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "\n",
    "results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "results['batch_ASW'] = me.silhouette_batch(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, verbose=verbose)\n",
    "print(\"batch_ASW: \" + str(results['batch_ASW']))\n",
    "\n",
    "type_ = \"knn\" if output_type == \"graph\" else None\n",
    "results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "    type_=type_, verbose=verbose)\n",
    "print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "# results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "#     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# print(\"iLISI: \" + str(results['iLISI']))\n",
    "results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "    subsample=subsample*100, verbose=verbose)\n",
    "print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "\n",
    "results['label_ASW'] = me.silhouette(adata, label_key=label_key, embed=embed)\n",
    "print(\"label_ASW: \" + str(results['label_ASW']))\n",
    "\n",
    "results['il_score_ASW'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, cluster=False, verbose=verbose)\n",
    "print(\"il_score_ASW: \" + str(results['il_score_ASW']))\n",
    "\n",
    "results['il_score_f1'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, cluster=True, verbose=verbose)\n",
    "print(\"il_score_f1: \" + str(results['il_score_f1']))\n",
    "\n",
    "results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "    subsample=subsample*100,  verbose=verbose)\n",
    "print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# results = {k: float(v) for k, v in results.items()}\n",
    "# results['batch_score'] = np.nanmean([results['graph_conn'], results['batch_ASW'], results['kBET'], results['iLISI']])\n",
    "# results['bio_score'] = np.nanmean([results['label_ASW'], results['il_score_ASW'], results['il_score_f1'], \n",
    "#                                    results['NMI'], results['ARI'], results['cLISI']])\n",
    "# results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'graph_conn':     [results['graph_conn']],\n",
    "    'batch_ASW':      [results['batch_ASW']],\n",
    "    'kBET':           [results['kBET']],\n",
    "    'iLISI':          [results['iLISI']],\n",
    "    # 'batch_score':    [results['batch_score']],\n",
    "    'label_ASW':      [results['label_ASW']],\n",
    "    'il_score_ASW':   [results['il_score_ASW']],\n",
    "    'il_score_f1':    [results['il_score_f1']],   \n",
    "    'NMI':            [results['NMI']],\n",
    "    'ARI':            [results['ARI']],\n",
    "    'cLISI':          [results['cLISI']],\n",
    "    # 'bio_score':      [results['bio_score']],\n",
    "    # 'overall_score':  [results['overall_score']]\n",
    "})\n",
    "print(df)\n",
    "utils.mkdirs(result_dir, remove_old=False)\n",
    "df.to_excel(pj(result_dir, \"metrics_batch_bio.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = {}\n",
    "\n",
    "# print('clustering...')\n",
    "# res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "#     cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "\n",
    "# results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "# print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "# results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "# print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "# type_ = \"knn\" if output_type == \"graph\" else None\n",
    "# results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "#     type_=type_, verbose=verbose)\n",
    "# print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "# results['il_score_f1'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "#     embed=embed, cluster=True, verbose=verbose)\n",
    "# print(\"il_score_f1: \" + str(results['il_score_f1']))\n",
    "\n",
    "# results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "# print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "# # results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "# #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# # print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "#     subsample=subsample*100,  verbose=verbose)\n",
    "# print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "# # results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "# #     subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "# # print(\"iLISI: \" + str(results['iLISI']))\n",
    "# results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "#     subsample=subsample*100, verbose=verbose)\n",
    "# print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "# results = {k: float(v) for k, v in results.items()}\n",
    "# results['batch_score'] = np.nanmean([results['iLISI'], results['graph_conn'], results['kBET']])\n",
    "# results['bio_score'] = np.nanmean([results['NMI'], results['ARI'], results['il_score_f1'], results['cLISI']])\n",
    "# results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'iLISI':          [results['iLISI']],\n",
    "#     'graph_conn':     [results['graph_conn']],\n",
    "#     'kBET':           [results['kBET']],\n",
    "#     'batch_score':    [results['batch_score']],\n",
    "#     'NMI':            [results['NMI']],\n",
    "#     'ARI':            [results['ARI']],\n",
    "#     'il_score_f1':    [results['il_score_f1']],\n",
    "#     'cLISI':          [results['cLISI']],\n",
    "#     'bio_score':      [results['bio_score']],\n",
    "#     'overall_score':  [results['overall_score']]\n",
    "# })\n",
    "# print(df)\n",
    "# utils.mkdirs(result_dir, remove_old=False)\n",
    "# df.to_excel(pj(result_dir, \"metrics_batch_bio.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
