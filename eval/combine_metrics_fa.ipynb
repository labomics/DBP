{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/data/DBP_sa_bc/\")\n",
    "from os.path import join as pj\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append(\"modules\")\n",
    "import utils\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--tasks', type=str, nargs='+',  default=[\"dogma_full\", \"dogma_paired_full\", \n",
    "#     \"dogma_paired_abc\", \"dogma_paired_ab\",  \"dogma_paired_ac\", \"dogma_paired_bc\",\n",
    "#     \"dogma_single_full\", \"dogma_single\"])\n",
    "parser.add_argument('--tasks', type=str, nargs='+',  default=[\"lung_ts\"])\n",
    "parser.add_argument('--method', type=str, default='DBP_sa_bc')\n",
    "# parser.add_argument('--mosaic', type=int, default=1)\n",
    "parser.add_argument('--experiment', type=str, default='e52')\n",
    "parser.add_argument('--model', type=str, default='default')\n",
    "parser.add_argument('--init_model', type=str, default='sp_latest')\n",
    "o, _ = parser.parse_known_args()  # for python interactive\n",
    "# o = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_l1</th>\n",
       "      <th>k4</th>\n",
       "      <th>l0</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>0.012944</td>\n",
       "      <td>66.298203</td>\n",
       "      <td>0.579838</td>\n",
       "      <td>0.194615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        l2_l1         k4        l0  distances\n",
       "DBP  0.012944  66.298203  0.579838   0.194615"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# midas_embed results\n",
    "df_batch_bio_embed = {}\n",
    "o.tasks = [o.tasks[0]]\n",
    "for task in o.tasks:\n",
    "    df_batch_bio_embed[task] = pd.read_excel(pj(\"result\", \"comparison\", task, o.method, o.experiment, o.init_model, \"metrics_fa.xlsx\"))\n",
    "    df_batch_bio_embed[task].rename(index={0: task}, inplace=True)\n",
    "df_batch_bio_embed_cat = pd.concat(df_batch_bio_embed.values(), axis=0)\n",
    "\n",
    "# df_batch_bio_embed_cat[[\"task\"]] = df_batch_bio_embed_cat.index\n",
    "df_batch_bio_embed_cat.rename(index={i: \"DBP\" for i in df_batch_bio_embed_cat.index}, inplace=True)\n",
    "df_batch_bio_embed_cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sota results\n",
    "methods = [\n",
    "    # \"harmony\",\n",
    "    \"liger\",\n",
    "    \"mofa\",\n",
    "    # \"scanorama_embed\",\n",
    "    # \"seurat_cca\",\n",
    "    # \"seurat_rpca\",\n",
    "    \"LDVAE\",\n",
    "    \"scETM\"\n",
    "    # \"pca\",\n",
    "]\n",
    "\n",
    "df_sota = {}\n",
    "for method in methods:\n",
    "    if \"DBP_sa_bc\" in method:\n",
    "        df_sota[method] = pd.read_excel(pj(\"result\", \"comparison\", o.tasks[0], method, o.experiment, o.init_model, \"metrics_fa.xlsx\"))\n",
    "    else:\n",
    "        df_sota[method] = pd.read_excel(pj(\"result\", \"comparison\", o.tasks[0], method, \"metrics_fa.xlsx\"))\n",
    "    df_sota[method].rename(index={0: method}, inplace=True)\n",
    "df_sota_cat = pd.concat(df_sota.values(), axis=0)\n",
    "\n",
    "# df_sota_cat[[\"task\"]] = o.tasks\n",
    "# df_sota_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2_l1</th>\n",
       "      <th>k4</th>\n",
       "      <th>l0</th>\n",
       "      <th>distances</th>\n",
       "      <th>mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>0.894909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liger</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666401</td>\n",
       "      <td>0.61546</td>\n",
       "      <td>0.316195</td>\n",
       "      <td>0.649514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mofa</th>\n",
       "      <td>0.292310</td>\n",
       "      <td>0.421385</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDVAE</th>\n",
       "      <td>0.074833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.138186</td>\n",
       "      <td>0.053255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scETM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029830</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.172612</td>\n",
       "      <td>0.050610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          l2_l1        k4       l0  distances  mean_score\n",
       "DBP    0.894909  1.000000  1.00000   1.000000    0.973727\n",
       "liger  1.000000  0.666401  0.61546   0.316195    0.649514\n",
       "mofa   0.292310  0.421385  0.00000   0.000000    0.178424\n",
       "LDVAE  0.074833  0.000000  0.00000   0.138186    0.053255\n",
       "scETM  0.000000  0.029830  0.00000   0.172612    0.050610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = pd.concat([df_batch_bio_embed_cat, df_sota_cat], axis=0)\n",
    "df_cat = (df_cat-df_cat.min(axis=0))/(df_cat.max(axis=0)-df_cat.min(axis=0))\n",
    "\n",
    "df_mean_cat = copy.deepcopy(df_cat)\n",
    "df_mean_cat[\"mean_score\"] = df_cat[[\"l2_l1\", \"k4\", \"l0\"]].mean(axis=1)\n",
    "# df_mean_cat[\"bio_score\"] = df_cat[[\"label_ASW\", \"il_score_ASW\", \"il_score_f1\", \"NMI\", \"ARI\", \"cLISI\"]].mean(axis=1)\n",
    "# df_mean_cat[\"overall_score\"] = 0.4 * df_mean_cat[\"batch_score\"] + 0.6 * df_mean_cat[\"bio_score\"]\n",
    "# df_mean_cat = df_mean_cat[[\"graph_conn\", \"batch_ASW\", \"kBET\", \"iLISI\", \"batch_score\", \"label_ASW\", \"il_score_ASW\", \"il_score_f1\", \"NMI\", \"ARI\", \"cLISI\", \"bio_score\", \"overall_score\"]]\n",
    "df_mean_cat.sort_values(\"mean_score\", ascending=False, inplace=True)\n",
    "# df_mean_cat\n",
    "df_mean_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = pj(\"eval\", \"plot\", \"data\")\n",
    "utils.mkdir(out_dir, remove_old=False)\n",
    "# df_mean_cat.to_excel(pj(out_dir, \"scib_metrics_dbp_\"+o.tasks[0].split(\"_\")[0]+\"_\"+o.init_model+\".xlsx\"))\n",
    "df_mean_cat.to_excel(pj(out_dir, \"fa_metrics_\"+o.tasks[0]+\"_\"+o.method+\"_\"+o.experiment+\"_\"+o.init_model+\".xlsx\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
